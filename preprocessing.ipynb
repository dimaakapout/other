{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir_path = os.getcwd() # Абс путь текущего рабочего каталога\n",
    "trainDir_path = os.path.join(workDir_path, 'train') # Абс путь в папку с TrainData\n",
    "testDir_path = os.path.join(workDir_path, 'test') # Абс путь в папку с TestData\n",
    "\n",
    "parquetsTrain = os.listdir(path = trainDir_path) # Список \"паркетов\"\n",
    "parquetsTest = os.listdir(path = testDir_path) # Список \"паркетов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# категор фичи\n",
    "cat_columns = ['currency', 'operation_kind', 'operation_type_group', 'ecommerce_flag', 'payment_system',\n",
    "               'income_flag', 'country', 'mcc_category', 'city', 'card_type', 'mcc', 'operation_type']\n",
    "\n",
    "# числовые фичи\n",
    "num_columns = ['amnt', 'hour','hour_diff', 'days_before', 'day_of_week']\n",
    "\n",
    "# фичи с которыми работаем\n",
    "columns = ['app_id'] + cat_columns + num_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отладка func\n",
    "# path = os.path.join(trainDir_path, parquetsTrain[0]) # Абс путь до \"паркета\"\n",
    "# X = pd.read_parquet(path)\n",
    "# a=17.8209044625170474069 #Заточили под 100\n",
    "# X['amnt'] = np.exp(X['amnt']*a)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_table_feature2(df, names, aggfuncs=[], normalize=False):\n",
    "    \"\"\"\n",
    "    ....\n",
    "    \"\"\"\n",
    "    tmp = pd.pivot_table(df, values='amnt', index='app_id', columns=names, aggfunc=['sum', 'mean'] + aggfuncs )\n",
    "#     names = pd.Series(names).apply('sum')\n",
    "    tmp.columns = [str('_').join(names) + '__' + str('___').join([str(x)for x in i]) for i in tmp.columns]\n",
    "    if normalize: # особо и не нужна \n",
    "        tmp = tmp.div(tmp.sum(axis=1), axis=0)\n",
    "        tmp.fillna(0.0)\n",
    "    tmp = tmp.reset_index()\n",
    "\n",
    "    return (tmp.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(data, cat_columns=cat_columns, num_columns=num_columns, name='None'):\n",
    "    '''\n",
    "    Препроцессинг данных\n",
    "    '''\n",
    "    coef = 17.8209044625170474069\n",
    "    data['amnt'] = np.exp(data['amnt']*coef)-1\n",
    "    \n",
    "    a = make_pivot_table_feature2(data, ['income_flag', 'mcc_category'], aggfuncs=['std'])\n",
    "    b = make_pivot_table_feature2(data, ['income_flag', 'operation_kind'], aggfuncs=['std'])\n",
    "    c = make_pivot_table_feature2(data, ['income_flag', 'day_of_week', 'operation_type_group'], aggfuncs=['std'])\n",
    "    return a.merge(b).merge(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(folder_name, mode, output_name, columns=columns, func=func):\n",
    "    '''\n",
    "    folder_name - папка где хранятся обработанные файлы\n",
    "    mode = train/test\n",
    "    output_name - имя выходного файла\n",
    "    columns - какие признаки исходного датасета читаем\n",
    "    func - функция предобработки признаков\n",
    "    return: сохраняет конечный файл в формате csv/parquet\n",
    "    '''\n",
    "    \n",
    "    # Режим работы\n",
    "    if mode == 'train':\n",
    "        parquets = parquetsTrain\n",
    "        dataDir_path = trainDir_path\n",
    "    elif mode == 'test':\n",
    "        parquets = parquetsTest\n",
    "        dataDir_path = testDir_path\n",
    "    \n",
    "    # Проверка от создания уже существующей папки\n",
    "    if os.path.isdir(folder_name) is True:\n",
    "        raise BaseException('Папка уже существует, выбери другое имя')\n",
    "    \n",
    "    # Создаем каталог\n",
    "    os.mkdir(folder_name)\n",
    "    \n",
    "    # Для каждого паркета запускаем обработчик   \n",
    "    for parquet in parquets:\n",
    "        path = os.path.join(dataDir_path, parquet) # Абс путь до \"паркета\"\n",
    "        name = path.split('\\\\')[-1][:8] # получаем имя\n",
    "        data = pd.read_parquet(path, columns=columns) \n",
    "        \n",
    "        # Генерация фичей\n",
    "        data = func(data, name=name)\n",
    "        \n",
    "        # Сохраняем данные\n",
    "        data.to_parquet('./{0}/{1}.csv'.format(folder_name, name))        \n",
    "        print('{0} обработан'.format(name))\n",
    "    # Склейка датасета\n",
    "    dir_path = os.path.join(workDir_path, folder_name) # Директория с предобработанными данными\n",
    "    parquets = os.listdir(path = dir_path) # Список \"паркетов\"\n",
    "    \n",
    "    data = False # DATA\n",
    "    p = 0\n",
    "    for parquet in parquets:\n",
    "        path = os.path.join(dir_path, parquet) # Абс путь до \"паркета\"\n",
    "        if data is False: # Для первого \"паркета\"\n",
    "            data = pd.read_parquet(path)\n",
    "            continue\n",
    "            \n",
    "        _ = pd.read_parquet(path)\n",
    "        data = pd.concat([data, _]) # Соединить таблички\n",
    "        p+=1\n",
    "        print(p)\n",
    "    print('Сохраняю')\n",
    "    data.to_parquet('{0}.parquet'.format(output_name)) # ДАННЫЕ СОХРАНЯЮТСЯ В ФОРМАТЕ parquet! а не csv! pd.read_parquet()!\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_000 обработан\n",
      "part_001 обработан\n",
      "part_002 обработан\n",
      "part_003 обработан\n",
      "part_004 обработан\n",
      "part_005 обработан\n",
      "part_006 обработан\n",
      "part_007 обработан\n",
      "part_008 обработан\n",
      "part_009 обработан\n",
      "part_010 обработан\n",
      "part_011 обработан\n",
      "part_012 обработан\n",
      "part_013 обработан\n",
      "part_014 обработан\n",
      "part_015 обработан\n",
      "part_016 обработан\n",
      "part_017 обработан\n",
      "part_018 обработан\n",
      "part_019 обработан\n",
      "part_020 обработан\n",
      "part_021 обработан\n",
      "part_022 обработан\n",
      "part_023 обработан\n",
      "part_024 обработан\n",
      "part_025 обработан\n",
      "part_026 обработан\n",
      "part_027 обработан\n",
      "part_028 обработан\n",
      "part_029 обработан\n",
      "part_030 обработан\n",
      "part_031 обработан\n",
      "part_032 обработан\n",
      "part_033 обработан\n",
      "part_034 обработан\n",
      "part_035 обработан\n",
      "part_036 обработан\n",
      "part_037 обработан\n",
      "part_038 обработан\n",
      "part_039 обработан\n",
      "part_040 обработан\n",
      "part_041 обработан\n",
      "part_042 обработан\n",
      "part_043 обработан\n",
      "part_044 обработан\n",
      "part_045 обработан\n",
      "part_046 обработан\n",
      "part_047 обработан\n",
      "part_048 обработан\n",
      "part_049 обработан\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Сохраняю\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "read_data(folder_name='test-26-12-2020', mode='test', output_name='test_data26122020_dopFeatures') # Обработка теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Потом запустить тест на обработку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_000 обработан\n",
      "part_001 обработан\n",
      "part_002 обработан\n",
      "part_003 обработан\n",
      "part_004 обработан\n",
      "part_005 обработан\n",
      "part_006 обработан\n",
      "part_007 обработан\n",
      "part_008 обработан\n",
      "part_009 обработан\n",
      "part_010 обработан\n",
      "part_011 обработан\n",
      "part_012 обработан\n",
      "part_013 обработан\n",
      "part_014 обработан\n",
      "part_015 обработан\n",
      "part_016 обработан\n",
      "part_017 обработан\n",
      "part_018 обработан\n",
      "part_019 обработан\n",
      "part_020 обработан\n",
      "part_021 обработан\n",
      "part_022 обработан\n",
      "part_023 обработан\n",
      "part_024 обработан\n",
      "part_025 обработан\n",
      "part_026 обработан\n",
      "part_027 обработан\n",
      "part_028 обработан\n",
      "part_029 обработан\n",
      "part_030 обработан\n",
      "part_031 обработан\n",
      "part_032 обработан\n",
      "part_033 обработан\n",
      "part_034 обработан\n",
      "part_035 обработан\n",
      "part_036 обработан\n",
      "part_037 обработан\n",
      "part_038 обработан\n",
      "part_039 обработан\n",
      "part_040 обработан\n",
      "part_041 обработан\n",
      "part_042 обработан\n",
      "part_043 обработан\n",
      "part_044 обработан\n",
      "part_045 обработан\n",
      "part_046 обработан\n",
      "part_047 обработан\n",
      "part_048 обработан\n",
      "part_049 обработан\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Сохраняю\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "read_data(folder_name='train-26-12-2020', mode='train', output_name='train_data26122020') # обработка трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
